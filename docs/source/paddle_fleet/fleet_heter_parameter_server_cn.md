# 6.使用Fleet进行异构参数服务器训练

## 什么是异构参数服务器？

在开始使用`异构`参数服务器前，您需要先了解[参数服务器](链接待更新)的基本知识。我们先进行简单回顾：

### 参数服务器的应用领域以及解决的问题

参数服务器集中应用在`NLP`、`推荐` 以及 `搜索`领域，其主要针对以下两个问题：

1. **大数据**：

    原始数据集庞大，动辄几百G的数据量，单机训练速度难以承受，需要依赖数据并行加速训练，以此解决大数据的问题。

2. **大参数**：
   
    在上述场景中，数据量大的同时，伴随着特征的稀疏性，开发者们通常使用`Embedding`技术来将业务场景中的高维稀疏特征向量转化为低维的稠密特征向量。
    
    在工业场景中，该`Embedding`参数的维度往往是亿级，占用的存储空间在上百Gi，单机内存以及单卡显存无法承受，因此使用参数服务器模式，将该参数分片放到各个`Server`上，`Wroker`训练模型时，仅请求当前batch数据需要用到的参数，以此解决大参数的问题。

### 传统参数服务器的局限

当前参数服务器的`Worker`节点，通常使用`CPU`或`GPU`机器完成模型训练中的前向与反向部分。

当`Worker`使用的设备确定，其硬件算力的配比也随之固定。固定的算力配比，在工业应用中，存在着以下问题：

1. **GPU机器IO有瓶颈**

    若训练的模型不复杂，如推荐领域常用的`DeepFM`、`LR`，网络计算耗时并不高，而数据读取(`IO`)的性能决定了网络训练的速度。在GPU机器上，在GPU的算力被充分利用前，CPU性能已经被数据IO部分榨干，导致网络训练速度无法进一步提升，GPU算力被浪费。

2. **CPU机器算力有瓶颈**

    CPU机器通常核心数较多，并且机器价格也更便宜，可以充分利用CPU多核的优势，在简单模型上极大的提升数据吞吐，整体训练达到较好的性能。但是，随着深度学习模型的日渐复杂，在一些计算能力要求高的模型中，比如`Bert`，计算能力严重不足，网络计算耗时极高。

### 异构参数服务器介绍

那么，可不可以动态调整机器配比？同时解决IO瓶颈以及算力瓶颈呢？

PaddlePaddle基于工业实践，创新性的提出了异构参数服务器，支持不同算力的芯片混合异构训练，如CPU、v100，p40，昆仑芯片，对不同算力的芯片高效利用，使得训练任务对设备不敏感，获得更高的加速效果。

<img src='./img/heter_overview.png' align="middle" />

#### 异构参数服务器基本原理

一个深度学习模型的训练过程可以拆分为三步：1、前向计算Loss；2、反向计算梯度；3、利用梯度更新参数。

参数服务器模式下，前向及反向步骤在`Worker`端(也称为`Trainer`)完成，参数更新在`Server`端完成。

异构参数服务器模式中，我们进一步拆分前向及反向，可以将embedding查表，输入数据的reshape等IO密集型的OP放置于`CPU-Trainer`，将fc，attention等计算密集型的OP放置于`Heter-Trainer`。

`CPU-Trainer`和`Heter-Trainer`之间会进行通信，交换网络运行所需要的上下文参数，两者协同完成前向和反向步骤，并将梯度发给`Server`，完成参数的更新。

<img src='./img/heter_example.png' align="middle" />


#### 异构参数服务器底层原理

- **单机训练的运行原理图**

<img src='./img/heter_single_program.png' align="middle" />

- **传统参数服务器的运行原理图**

<img src='./img/heter_async_program.png' align="middle" />

- **传统参数服务器的运行原理图**

<img src='./img/heter_program.png' align="middle" />

#### 异构参数服务器使用示例

#### 使用fleetrun启动异构参数服务器训练
