-----------  Configuration Arguments -----------
batch_size: 8
bert_config_path: data/large_config/bert_config.json
checkpoints: ./output
data_dir: /home/jingqinghe/test/Fleet/examples/recompute/bert/../../../benchmark/collective/bert/data/train
do_test: False
epoch: 100
generate_neg_sample: True
in_tokens: False
init_checkpoint: None
learning_rate: 0.0001
loss_scaling: 8.0
lr_scheduler: linear_warmup_decay
max_seq_len: 512
num_iteration_per_drop_scope: 10
num_threads: 2
num_train_steps: 1000000
profile: False
save_steps: 10000
skip_steps: 1
test_set_dir: None
use_cuda: True
use_fp16: False
use_mix_precision: False
use_recompute: False
validation_set_dir: /home/jingqinghe/test/Fleet/examples/recompute/bert/../../../benchmark/collective/bert/data/validation
validation_steps: 10000000000
verbose: False
vocab_path: data/large_config/vocab.txt
warmup_steps: 4000
weight_decay: 0.01
weight_sharing: True
------------------------------------------------
pretraining start
attention_probs_dropout_prob: 0.1
hidden_act: gelu
hidden_dropout_prob: 0.1
hidden_size: 1024
initializer_range: 0.02
intermediate_size: 4096
max_position_embeddings: 512
num_attention_heads: 16
num_hidden_layers: 24
type_vocab_size: 2
vocab_size: 30522
------------------------------------------------
2020-06-28 22:58:13,930-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.
/home/jingqinghe/python-gcc482-paddle/lib/python2.7/site-packages/paddle/fluid/layers/math_op_patch.py:276: UserWarning: /home/jingqinghe/test/Fleet/examples/recompute/bert/model/bert.py:106
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/jingqinghe/python-gcc482-paddle/lib/python2.7/site-packages/paddle/fluid/layers/math_op_patch.py:276: UserWarning: /home/jingqinghe/test/Fleet/examples/recompute/bert/model/bert.py:107
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/jingqinghe/python-gcc482-paddle/lib/python2.7/site-packages/paddle/fluid/layers/math_op_patch.py:276: UserWarning: /home/jingqinghe/test/Fleet/examples/recompute/bert/model/transformer_encoder.py:147
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/jingqinghe/python-gcc482-paddle/lib/python2.7/site-packages/paddle/fluid/layers/math_op_patch.py:276: UserWarning: /home/jingqinghe/test/Fleet/examples/recompute/bert/model/transformer_encoder.py:236
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/jingqinghe/python-gcc482-paddle/lib/python2.7/site-packages/paddle/fluid/clip.py:793: UserWarning: Caution! 'set_gradient_clip' is not recommended and may be deprecated in future! We recommend a new strategy: set 'grad_clip' when initializing the 'optimizer'. This method can reduce the mistakes, please refer to documention of 'optimizer'.
  warnings.warn("Caution! 'set_gradient_clip' is not recommended "
2020-06-28 22:58:20,086-WARNING: set nccl_comm_num=1 since you only have 1 node.
2020-06-28 22:58:20,086-WARNING: set use_hierarchical_allreduce=False since you only have 1 node.


API is deprecated since 2.0.0 Please use FleetAPI instead.
WIKI: https://github.com/PaddlePaddle/Fleet/blob/develop/markdown_doc/transpiler

        
2020-06-28 22:58:20,528-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.
Device count 2
W0628 22:58:24.444139 119688 device_context.cc:265] Please NOTE: device: 1, CUDA Capability: 70, Driver API Version: 10.1, Runtime API Version: 9.2
W0628 22:58:24.448402 119688 device_context.cc:273] device: 1, cuDNN Version: 7.4.
E0628 22:58:28.033180222  128240 tcp_server_posix.cc:64]     check for SO_REUSEPORT: {"created":"@1593356308.033163524","description":"SO_REUSEPORT unavailable on compiling system","file":"src/core/lib/iomgr/socket_utils_common_posix.cc","file_line":163}
I0628 22:58:28.034188 128240 grpc_server.cc:477] Server listening on 127.0.0.1:53156 successful, selected port: 53156
W0628 22:58:39.266880 119688 fuse_all_reduce_op_pass.cc:74] Find all_reduce operators: 398. To make the speed faster, some all_reduce ops are fused during training, after fusion, the number of all_reduce ops is 37.
Traceback (most recent call last):
  File "./train.py", line 420, in <module>
    train(args)
  File "./train.py", line 347, in train
    train_exe.run(fetch_list=[], program=train_program)
  File "/home/jingqinghe/python-gcc482-paddle/lib/python2.7/site-packages/paddle/fluid/executor.py", line 1074, in run
    return_merged=return_merged)
  File "/home/jingqinghe/python-gcc482-paddle/lib/python2.7/site-packages/paddle/fluid/executor.py", line 1175, in _run_impl
    return_merged=return_merged)
  File "/home/jingqinghe/python-gcc482-paddle/lib/python2.7/site-packages/paddle/fluid/executor.py", line 887, in _run_parallel
    tensors = exe.run(fetch_var_names, return_merged)._move_to_list()
KeyboardInterrupt
